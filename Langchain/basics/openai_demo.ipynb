{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Gemma Model"
      ],
      "metadata": {
        "id": "cR-LhRljMd7n"
      },
      "id": "cR-LhRljMd7n"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install some langchain packages"
      ],
      "metadata": {
        "id": "NPWFCezQuCYO"
      },
      "id": "NPWFCezQuCYO"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai\n",
        "!pip install langchain_community\n",
        "!pip install openai"
      ],
      "metadata": {
        "id": "CdrTp67quIEc"
      },
      "id": "CdrTp67quIEc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "IRVhMy__uTlK"
      },
      "id": "IRVhMy__uTlK"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import base64\n",
        "import getpass\n",
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "_set_env(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAptUqtluX6Q",
        "outputId": "4b2c10c2-be6c-4393-9d23-ad47a29e1570"
      },
      "id": "mAptUqtluX6Q",
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OPENAI_API_KEY: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.chat_models import ChatOpenAI\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "## The LLM piece is now changing to gemma\n",
        "llm=ChatOpenAI(model=\"gpt-4o\",api_key=OPENAI_API_KEY)\n",
        "\n",
        "## Everything else remains same!\n",
        "\n",
        "question = input(\"Enter the question\")\n",
        "response = llm.invoke(question)\n",
        "print(response.content)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X__7IPv6tXRy",
        "outputId": "b049791a-4ecf-4a9e-ac50-9a4809718c4f"
      },
      "id": "X__7IPv6tXRy",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-def0aed59d45>:5: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm=ChatOpenAI(model=\"gpt-4o\",api_key=OPENAI_API_KEY)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the questionWhat is capital of Germany\n",
            "The capital of Germany is Berlin.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}